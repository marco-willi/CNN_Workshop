{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - Workshop\n",
    "\n",
    "## CPU Version: recognizing small grayscale images of handwritten digits - MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules and Dataset\n",
    "Conveniently, Keras already contains the dataset as this one is often used to test machine learning algorithms, due to its small size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import array_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# add 3rd dimension (1 color channel)\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select images\n",
    "random.seed(23)\n",
    "random_ids = random.sample(population=range(0, x_train.shape[0]),k=5)\n",
    "random_imgs = x_train[random_ids, :]\n",
    "random_labels = y_train[random_ids]\n",
    "\n",
    "# display random images and their label as provided by the data set\n",
    "for i in range(0, len(random_ids)):\n",
    "    print(\"Label: %s\" % random_labels[i])\n",
    "    plt.imshow(array_to_img(random_imgs[i,:]).convert('L'), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators\n",
    "\n",
    "Keras ImageDataGenerator implements transformations, pre-processing and serving of image data during training. For example, streaming image batches from a directory while training a model. The data pre-processing & streaming is done on CPU, while the model training is done on GPU to increase efficiency (GPU version).\n",
    "\n",
    "Data augmentation is a process where images are artificially altered to create 'new'data that is similar to the original data. This helps to increase your data set size & to avoid overfitting. Data augmentation operations are: flipping, cropping & zooming.\n",
    "\n",
    "Data pre-processing operations like standardizations of pixel values have been shown to increase the efficiency of model training. Operations include: featurewise_center & featurewise_std_normalization.\n",
    "\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing of images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# data generator for training process\n",
    "datagen_train = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# data generator for testing\n",
    "# we don't need data augmentation here, but we need to pre-process it in the same way as the training data\n",
    "datagen_test = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "# this has to be done on the training data & is applied on both data generators\n",
    "datagen_train.fit(x_train)\n",
    "datagen_test.fit(x_train)\n",
    "\n",
    "# initialize flow from random data to show what pre-processing of images does\n",
    "random_datagen = datagen_train.flow(random_imgs, random_labels)\n",
    "\n",
    "# initialize flow from data\n",
    "test_datagen = datagen_test.flow(x_test, y_test)\n",
    "train_datagen = datagen_train.flow(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we show what the pre-processing does\n",
    "data_batch = test.next()\n",
    "for i in range(0, len(data_batch[1])):\n",
    "    print(\"Label: %s\" % data_batch[1][i])\n",
    "    plt.imshow(array_to_img(data_batch[0][i,:]).convert('L'), cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "Now we define a model architecture, which consists of sequential layers of operations. The 2 main blocks of a CNN are the convolutional part and the fully connected part.\n",
    "\n",
    "Convolutional layers: These layers extract features from the input (e.g. edges, corners, patterns). This block starts directly at the beginning (e.g. functions Conv2D()) and typically consists of convolution layers (Conv2d()), followed by an activation (nowadays ReLu activation), and a pooling layer (e.g. MaxPooling2D()). Multiple such constructs can be stacked.\n",
    "* https://keras.io/layers/convolutional/\n",
    "\n",
    "The fully connected part represents a classical neural network consisting of an input layer (Flatten()) which takes the features from the convolutional part, some hidden layer(s) (Dense()), and finally an output layer (Dense(), with an activation function that results in probabilities for classification tasks, like sigmoid or softmax).\n",
    "* https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# sequential model (layer based)\n",
    "model = Sequential\n",
    "# Convolutional layer over 2 dimensions\n",
    "# 32 filters, each with a size of 3x3 pixels\n",
    "# activation function is ReLU\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1), name=\"conv_1\"))\n",
    "# Aggregate data using max pooling (reduce size of feature maps)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_1\"))\n",
    "# randomly set 50% of all outputs to zero to prevent overfitting\n",
    "model.add(Dropout(0.5, name=\"drop_1\"))\n",
    "# this converts our 3D feature maps to a 1D feature vector\n",
    "model.add(Flatten(name=\"flatten\"))\n",
    "# fully connected layer with 128 output values\n",
    "model.add(Dense(128, activation='relu',name=\"dense_1\"))\n",
    "# randomly set 50% of all outputs to zero to prevent overfitting\n",
    "model.add(Dropout(0.5,name=\"drop_2\"))\n",
    "# softmax transformation (logistic regression) to obtain class probabilities\n",
    "model.add(Dense(10, activation='softmax', name=\"output\"))\n",
    "\n",
    "# to take a look at the model we can invoke this command\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation & training\n",
    "After the model architecture has been defined, we have to compile the model. Important parameters include the optimizer and the loss function. The loss function for binary classifications is 'binary_crossentropy', which is what the model is trying to minimize during the training process. The optimizer defines how the gradients and their updates are calculated. Changing the optimizer can have a great effect on model convergence, if for example one changes to the stochastic gradient descent optimizer and chooses a high learning rate it may be that the model never converges.\n",
    "\n",
    "* https://keras.io/optimizers/\n",
    "\n",
    "#### Epochs\n",
    "Number of full passes over the training data (increase this number to get a better model performance & incrased training time).\n",
    "#### Batch Size\n",
    "Number of images simultenously used to calculated one update of the gradients. 1 image is stochastic gradient descent (SGD), N>1 images is mini-batch gradient descent (usually between 32 and 256 images), using n images is gradient descent.\n",
    "#### Steps_per_epoch\n",
    "The number of batches as generated by the data generator to process per epoch. We divide the number of samples by the batch size to make one full pass over the training data per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# number of simulatenously processed images\n",
    "batch_size = 64\n",
    "\n",
    "# train the model\n",
    "model.fit_generator(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=train_datagen.n // batch_size,\n",
    "    epochs=2,\n",
    "    workers=2,\n",
    "    validation_data=test_datagen,\n",
    "    validation_steps=test_datagen.n // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "The model quickly learns how to distinct between different digits, you can see that by observing the accuracy during training time. So after only few epochs we can take a look at a few predictions of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test sample\n",
    "\n",
    "# get a test batch\n",
    "test_batch_data = test_datagen.next()\n",
    "\n",
    "# calculate predictions\n",
    "p_test = model.predict_on_batch(test_batch_data[0])\n",
    "\n",
    "# show some images and their prediction\n",
    "for i in range(0, len(test_batch_data[1])):\n",
    "    id_max = np.argmax(p_test[i])\n",
    "    max_val = np.max(p_test[i])\n",
    "    print(\"Predicted %s percent of being a %s, in reality is a %s\" %\n",
    "          (round(float(max_val * 100), 2), id_max, test_batch_data[1][i]))\n",
    "    plt.imshow(array_to_img(test_batch_data[0][i, :]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at some of the trained filters\n",
    "We can extract filters from the model and take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Visualization of the filters of VGG16, via gradient ascent in input space.\n",
    "\n",
    "This script can run on CPU in a few minutes (with the TensorFlow backend).\n",
    "\n",
    "Results example: http://i.imgur.com/4nj4KjN.jpg\n",
    "'''\n",
    "import numpy as np\n",
    "import time\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "# the name of the layer we want to visualize (from model.summary())\n",
    "layer_name = 'dense_1'\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(0, 8):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 0.1\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 1, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 1))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(3):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "\n",
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 3\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 1))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "print(img.shape)\n",
    "plt.imshow(array_to_img(img))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN) - Workshop\n",
    "\n",
    "## CPU Version: recognizing small grayscale images of handwritten digits - MNIST\n",
    "### Ideally suited to be run on a local laptop or PC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules and Dataset\n",
    "Conveniently, Keras already contains the dataset as this one is often used to test machine learning algorithms, due to its small size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import array_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# add 3rd dimension (1 color channel)\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select images\n",
    "random.seed(23)\n",
    "random_ids = random.sample(population=range(0, x_train.shape[0]),k=5)\n",
    "random_imgs = x_train[random_ids, :]\n",
    "random_labels = y_train[random_ids]\n",
    "\n",
    "# display random images and their label as provided by the data set\n",
    "for i in range(0, len(random_ids)):\n",
    "    print(\"Label: %s\" % random_labels[i])\n",
    "    plt.imshow(array_to_img(random_imgs[i,:]).convert('L'), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators\n",
    "\n",
    "Keras ImageDataGenerator implements transformations, pre-processing and serving of image data during training. For example, streaming image batches from a directory while training a model. The data pre-processing & streaming is done on CPU, while the model training is done on GPU to increase efficiency (GPU version).\n",
    "\n",
    "Data augmentation is a process where images are artificially altered to create 'new'data that is similar to the original data. This helps to increase your data set size & to avoid overfitting. Data augmentation operations are: flipping, cropping & zooming.\n",
    "\n",
    "Data pre-processing operations like standardizations of pixel values have been shown to increase the efficiency of model training. Operations include: featurewise_center & featurewise_std_normalization.\n",
    "\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing of images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# data generator for training process\n",
    "datagen_train = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# data generator for testing\n",
    "# we don't need data augmentation here, but we need to pre-process it in the same way as the training data\n",
    "datagen_test = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "# this has to be done on the training data & is applied on both data generators\n",
    "datagen_train.fit(x_train)\n",
    "datagen_test.fit(x_train)\n",
    "\n",
    "# initialize flow from random data to show what pre-processing of images does\n",
    "random_datagen = datagen_train.flow(random_imgs, random_labels)\n",
    "\n",
    "# initialize flow from data\n",
    "test_datagen = datagen_test.flow(x_test, y_test)\n",
    "train_datagen = datagen_train.flow(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we show what the pre-processing does\n",
    "data_batch = random_datagen.next()\n",
    "for i in range(0, len(data_batch[1])):\n",
    "    print(\"Label: %s\" % data_batch[1][i])\n",
    "    plt.imshow(array_to_img(data_batch[0][i,:]).convert('L'), cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not happy with the output, e.g. too crazy data augmentation, feel free to change the 'ImageDataGenerator' and run the cell again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "Now we define a model architecture, which consists of sequential layers of operations. The 2 main blocks of a CNN are the convolutional part and the fully connected part.\n",
    "\n",
    "Convolutional layers: These layers extract features from the input (e.g. edges, corners, patterns). This block starts directly at the beginning (e.g. functions Conv2D()) and typically consists of convolution layers (Conv2d()), followed by an activation (nowadays ReLu activation), and a pooling layer (e.g. MaxPooling2D()). Multiple such constructs can be stacked.\n",
    "* https://keras.io/layers/convolutional/\n",
    "\n",
    "The fully connected part represents a classical neural network consisting of an input layer (Flatten()) which takes the features from the convolutional part, some hidden layer(s) (Dense()), and finally an output layer (Dense(), with an activation function that results in probabilities for classification tasks, like sigmoid or softmax).\n",
    "* https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# sequential model (layer based)\n",
    "model = Sequential\n",
    "# Convolutional layer over 2 dimensions\n",
    "# 32 filters, each with a size of 3x3 pixels\n",
    "# activation function is ReLU\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1), name=\"conv_1\"))\n",
    "# Aggregate data using max pooling (reduce size of feature maps)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_1\"))\n",
    "# randomly set 50% of all outputs to zero to prevent overfitting\n",
    "model.add(Dropout(0.5, name=\"drop_1\"))\n",
    "# this converts our 3D feature maps to a 1D feature vector\n",
    "model.add(Flatten(name=\"flatten\"))\n",
    "# fully connected layer with 128 output values\n",
    "model.add(Dense(128, activation='relu',name=\"dense_1\"))\n",
    "# randomly set 50% of all outputs to zero to prevent overfitting\n",
    "model.add(Dropout(0.5,name=\"drop_2\"))\n",
    "# softmax transformation (logistic regression) to obtain class probabilities\n",
    "model.add(Dense(10, activation='softmax', name=\"output\"))\n",
    "\n",
    "# to take a look at the model we can invoke this command\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to change the architecture. \n",
    "* You could for example get rid of all convolutional layers and only use a 'classical' neural network and see what happens.\n",
    "* Another option is to add more convolutional layers or increase/decrease the number of filters.\n",
    "* You can also play around with the Dropout() layers to see whether overfitting really is a problem here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation & training\n",
    "After the model architecture has been defined, we have to compile the model. Important parameters include the optimizer and the loss function. The loss function for binary classifications is 'binary_crossentropy', which is what the model is trying to minimize during the training process. The optimizer defines how the gradients and their updates are calculated. Changing the optimizer can have a great effect on model convergence, if for example one changes to the stochastic gradient descent optimizer and chooses a high learning rate it may be that the model never converges.\n",
    "\n",
    "* https://keras.io/optimizers/\n",
    "\n",
    "#### Epochs\n",
    "Number of full passes over the training data (increase this number to get a better model performance & incrased training time).\n",
    "#### Batch Size\n",
    "Number of images simultenously used to calculated one update of the gradients. 1 image is stochastic gradient descent (SGD), N> and >1 images is mini-batch gradient descent (usually between 32 and 256 images), using all N images is gradient descent.\n",
    "#### Steps_per_epoch\n",
    "The number of batches as generated by the data generator to process per epoch. We divide the number of samples by the batch size to make one full pass over the training data per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# number of simulatenously processed images\n",
    "batch_size = 64\n",
    "\n",
    "# train the model\n",
    "model.fit_generator(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=train_datagen.n // batch_size,\n",
    "    epochs=2,\n",
    "    workers=2,\n",
    "    validation_data=test_datagen,\n",
    "    validation_steps=test_datagen.n // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to choose a different optimizer or to increase the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "The model quickly learns how to distinct between different digits, you can see that by observing the accuracy during training time. So after only few epochs we can take a look at a few predictions of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict on test sample\n",
    "\n",
    "# get a test batch\n",
    "test_batch_data = test_datagen.next()\n",
    "\n",
    "# calculate predictions\n",
    "p_test = model.predict_on_batch(test_batch_data[0])\n",
    "\n",
    "# show some images and their prediction\n",
    "for i in range(0, len(test_batch_data[1])):\n",
    "    id_max = np.argmax(p_test[i])\n",
    "    max_val = np.max(p_test[i])\n",
    "    print(\"Predicted %s percent of being a %s, in reality is a %s\" %\n",
    "          (round(float(max_val * 100), 2), id_max, test_batch_data[1][i]))\n",
    "    plt.imshow(array_to_img(test_batch_data[0][i, :]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
